// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// function-calling shows an example of OpenAPI Function Call
//
// This Function Call involves 3 messages:
// - ask the model to generate a Function Call request
// - call the Open API service (simulated in this example)
// - ask the model to interpret the Function Call response
package main

// [START aiplatform_gemini_function_calling]
import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"os"

	"cloud.google.com/go/vertexai/genai"
)

func main() {
	projectID := os.Getenv("GOOGLE_CLOUD_PROJECT")
	location := "us-central1"
	modelName := "gemini-pro"

	prompt := "What's the weather like in Paris?"

	if projectID == "" {
		log.Fatal("require environment variable GOOGLE_CLOUD_PROJECT")
	}

	err := weather(os.Stdout, prompt, projectID, location, modelName)
	if err != nil {
		log.Fatalf("unable to generate: %v", err)
	}
}

// weather opens a chat session and sends 2 messages to the model:
// - first, to convert a text into a structured Function Call request
// - second, to convert a structured Function Call response into natural language
func weather(w io.Writer, prompt, projectID, location, modelName string) error {
	ctx := context.Background()
	client, err := genai.NewClient(ctx, projectID, location)
	if err != nil {
		return fmt.Errorf("unable to create client: %v", err)
	}
	defer client.Close()

	model := client.GenerativeModel(modelName)

	params := &genai.Schema{
		Type: genai.TypeObject,
		Properties: map[string]*genai.Schema{
			"location": {
				Type:        genai.TypeString,
				Description: "location",
			},
		},
	}

	fundecl := &genai.FunctionDeclaration{
		Name:        "getCurrentWeather",
		Description: "Get the current weather in a given location",
		Parameters:  params,
	}

	model.Tools = []*genai.Tool{
		{FunctionDeclarations: []*genai.FunctionDeclaration{fundecl}},
	}

	chat := model.StartChat()

	fmt.Fprintf(w, "Question: %s\n", prompt)
	resp, err := chat.SendMessage(ctx, genai.Text(prompt))
	if err != nil {
		return err
	}
	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return fmt.Errorf("empty response from model")
	}

	// The model has returned a function call to the declared
	// function `getCurrentWeather` with "Paris" as the value for the
	// argument `location`.
	rb, _ := json.MarshalIndent(resp.Candidates[0].Content.Parts[0], "", "  ")
	fmt.Fprintf(w, "Function Call generated by the model:\n%s\n\n", string(rb))

	// Create a Function Call response, to simulate the result of a call to a
	// real service
	funresp := &genai.FunctionResponse{
		Name: "getCurrentWeather",
		Response: map[string]any{
			"currentWeather": "sunny",
		},
	}
	rb, _ = json.MarshalIndent(funresp, "", "  ")
	fmt.Fprintf(w, "Function Call response sent to the model:\n%s\n\n", string(rb))

	// And provide the Function Call response to the model
	resp, err = chat.SendMessage(ctx, funresp)
	if err != nil {
		return err
	}
	if len(resp.Candidates) == 0 || len(resp.Candidates[0].Content.Parts) == 0 {
		return fmt.Errorf("empty response from model")
	}

	// The model has taken the function call response as input, and has
	// reformulated the response to the user.
	rb, _ = json.MarshalIndent(resp.Candidates[0].Content.Parts[0], "", "  ")
	fmt.Fprintf(w, "Answer generated by the model:\n%s\n", string(rb))

	return nil
}

// [END aiplatform_gemini_function_calling]
